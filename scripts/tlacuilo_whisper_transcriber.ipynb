{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have ffmpeg installed locally\n",
    "import whisper    \n",
    "# Initialize Whisper model\n",
    "model = whisper.load_model(\"large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watching directory: ../audio_files_drop\n"
     ]
    }
   ],
   "source": [
    "# this part will continuously watch the audio_files_drop folder for new audio\n",
    "# and process, transcribe and fix common mispelling you may list in doc/whisper_errors.xlsx\n",
    "# transcript is placed in transcripts folder and the audio in processed_audio folder \n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import pandas as pd\n",
    "import re\n",
    "from pydub import AudioSegment \n",
    "\n",
    "# Function to load error corrections from the Excel file\n",
    "def load_corrections(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    corrections = dict(zip(df['error'], df['correction']))\n",
    "    return corrections\n",
    "\n",
    "# Function to replace errors in text with case insensitivity\n",
    "def clean_text(text, corrections):\n",
    "    for error, correction in corrections.items():\n",
    "        # Use re.sub for case-insensitive replacement\n",
    "        text = re.sub(re.escape(error), correction, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "class AudioFileHandler(FileSystemEventHandler):\n",
    "    def __init__(self, model, corrections, output_dir, processed_dir):\n",
    "        self.model = model\n",
    "        self.corrections = corrections\n",
    "        self.output_dir = output_dir\n",
    "        self.processed_dir = processed_dir\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if not event.is_directory:\n",
    "            self.process_file(event.src_path)\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        try:\n",
    "            # Check if the file is an audio file\n",
    "            if file_path.lower().endswith(('.wav', '.mp3', '.m4a')):\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                convert = False\n",
    "\n",
    "                # Convert audio file to WAV if necessary\n",
    "                if not file_path.lower().endswith('.wav'):\n",
    "                    audio = AudioSegment.from_file(file_path)\n",
    "                    output_audio_file = file_path[:-3] + \"wav\"\n",
    "                    audio.export(output_audio_file, format=\"wav\")\n",
    "                    convert = True\n",
    "                else:\n",
    "                    output_audio_file = file_path\n",
    "\n",
    "                # Calculate estimated transcription time\n",
    "                audio_length = AudioSegment.from_file(output_audio_file).duration_seconds\n",
    "                estimated_time = int(audio_length / 60)  # Estimated time in minutes\n",
    "\n",
    "                # Extract basename and sanitize it for filename\n",
    "                audio_basename = os.path.basename(file_path)\n",
    "                sanitized_basename = re.sub(r'[^\\w\\-_\\. ]', '_', audio_basename)\n",
    "\n",
    "                # Create a temporary status file in the drop folder\n",
    "                status_file = os.path.join(os.path.dirname(file_path), \n",
    "                                           f\"transcription started for {sanitized_basename} - estimated run time {estimated_time} mins.txt\")\n",
    "                with open(status_file, \"w\") as f:\n",
    "                    f.write(f\"Transcription for {os.path.basename(file_path)} started.\\n\")\n",
    "                    f.write(f\"Estimated run time: {estimated_time} mins.\\n\")\n",
    "                \n",
    "                print(f\"Created status file: {status_file}\")\n",
    "\n",
    "                # Transcribe audio using Whisper\n",
    "                result = self.model.transcribe(output_audio_file)\n",
    "\n",
    "                # Extract transcription text\n",
    "                transcription_text = result['text']\n",
    "\n",
    "                # Clean the transcription text\n",
    "                transcription_text = clean_text(transcription_text, self.corrections)\n",
    "\n",
    "                # Save transcription to a file\n",
    "                transcript_file = os.path.join(self.output_dir, os.path.basename(file_path) + '.txt')\n",
    "                with open(transcript_file, \"w\") as f:\n",
    "                    f.write(transcription_text)\n",
    "\n",
    "                print(f\"Transcription saved to: {transcript_file}\")\n",
    "\n",
    "                # Move the processed audio file to another folder\n",
    "                shutil.move(file_path, os.path.join(self.processed_dir, os.path.basename(file_path)))\n",
    "\n",
    "                # If conversion occurred, delete the converted file \n",
    "                if convert:\n",
    "                    os.remove(output_audio_file)\n",
    "\n",
    "                print(f\"Moved {file_path} to {self.processed_dir}\")\n",
    "\n",
    "                # Delete the status file after completion\n",
    "                os.remove(status_file)\n",
    "\n",
    "                print(f\"Deleted status file: {status_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory to watch for new files\n",
    "    watch_dir = \"../audio_files_drop\"  # Directory to watch for new files\n",
    "    output_dir = \"../transcripts\"  # Directory to save transcripts\n",
    "    processed_dir = \"../processed_audios\"  # Directory to move processed audio files\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize Whisper model\n",
    "    #model = whisper.load_model(\"large-v2\")\n",
    "\n",
    "    # Load error corrections from the Excel file\n",
    "    corrections_file = \"../doc/whisper_errors.xlsx\"  # list common whisper errors and their correction\n",
    "    corrections = load_corrections(corrections_file)\n",
    "\n",
    "    # Set up observer and event handler for the folder\n",
    "    observer = Observer()\n",
    "    event_handler = AudioFileHandler(model, corrections, output_dir, processed_dir)\n",
    "    observer.schedule(event_handler, path=watch_dir, recursive=False)\n",
    "\n",
    "    observer.start()\n",
    "\n",
    "    print(f\"Watching directory: {watch_dir}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "\n",
    "    observer.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
